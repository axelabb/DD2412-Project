{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,Permute, Reshape, Conv2D, BatchNormalization, Activation,Add,AveragePooling2D,Flatten,Dense\n",
    "import time\n",
    "from tensorflow.keras.regularizers import l2,l1_l2\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.metrics import Mean,SparseCategoricalAccuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self,X,y,batch_size,batch_rep,inp_rep_prob,ensemble_size,training,shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size //batch_rep\n",
    "        self.shuffle = shuffle\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.batch_rep = batch_rep\n",
    "        self.inp_rep_prob = inp_rep_prob\n",
    "        self.n = X.shape[0]\n",
    "        self.training = training\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            idxs = np.arange(self.n)\n",
    "            np.random.shuffle(idxs)\n",
    "            self.X = self.X[idxs]\n",
    "            self.y = self.y[idxs]\n",
    "\n",
    "    def __get_train_data(self,imgs,labels):\n",
    "\n",
    "        batch_rep = np.tile(np.arange(imgs.shape[0]),[self.batch_rep])\n",
    "        np.random.shuffle(batch_rep)\n",
    "        input_shuffle=int(batch_rep.shape[0] * (1. - self.inp_rep_prob))\n",
    "        #Kan detta göras bättre?\n",
    "        shuffle_idxs = [np.concatenate([np.random.permutation( batch_rep[:input_shuffle]), batch_rep[input_shuffle:]]) for _ in range(self.ensemble_size)]\n",
    "\n",
    "        imgs = np.stack([np.take(imgs, indxs, axis=0) for indxs in shuffle_idxs], axis=1)\n",
    "        labels = np.stack([np.take(labels, indxs, axis=0) for indxs in shuffle_idxs], axis=1)\n",
    "        \n",
    "        return imgs, labels\n",
    "\n",
    "    def __get_test_data(self,imgs,labels):\n",
    "        imgs = np.tile(np.expand_dims(imgs, 1), [1, self.ensemble_size, 1, 1, 1])\n",
    "        \n",
    "        return imgs, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgs = self.X[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        labels = self.y[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        if self.training:\n",
    "            imgs, labels = self.__get_train_data(imgs,labels)\n",
    "        else:\n",
    "            imgs,labels = self.__get_test_data(imgs,labels)\n",
    "        return  imgs, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(input,filters,strides,l_2):\n",
    "    y = input\n",
    "    x = BatchNormalization(momentum=0.9,epsilon=1e-5,beta_regularizer=l2(l_2),gamma_regularizer=l2(l_2))(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters,3,strides=strides,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(x)\n",
    "    x = BatchNormalization(momentum=0.9,epsilon=1e-5,beta_regularizer=l2(l_2),gamma_regularizer=l2(l_2))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters,3,strides=1,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(x)\n",
    "    \n",
    "    if not x.shape.is_compatible_with(y.shape):\n",
    "        y = Conv2D(filters,1,strides=strides,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(input)\n",
    "\n",
    "    return Add()([x,y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_group(input,filters,strides,n_blocks,l_2):\n",
    "    x = basic_block(input,filters,strides,l_2)\n",
    "    for _ in range(n_blocks-1):\n",
    "        x = basic_block(x,filters,1,l_2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_resnet(input_shape,d,w_mult,n_classes,l_2=0):\n",
    "    n_blocks = (d - 4) // 6\n",
    "    input_shape = list(input_shape)\n",
    "    ensemble_size = input_shape[0]\n",
    "\n",
    "    input = Input(shape=input_shape)\n",
    "\n",
    "    x = Permute([2,3,4,1])(input)\n",
    "\n",
    "    # Reshape so that each subnetwork has 3 channels\n",
    "    x = Reshape(input_shape[1:-1] + [input_shape[-1] * ensemble_size])(x)\n",
    "\n",
    "    x = Conv2D(16,3,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(x)\n",
    "\n",
    "    for strides, filters in zip([1, 2, 2], [16, 32, 64]):\n",
    "        x = res_group(x,filters*w_mult,strides,n_blocks,l_2)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9,epsilon=1e-5,beta_regularizer=l2(l_2),gamma_regularizer=l2(l_2))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(n_classes*ensemble_size,kernel_initializer='he_normal',activation=None,kernel_regularizer=l2(l_2),bias_regularizer=l2(l_2))(x)\n",
    "    x = Reshape([ensemble_size,n_classes])(x)\n",
    "    \n",
    "    return tf.keras.Model(input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLL(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "        nll = tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(tf.keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, n_classes,name=\"Accuracy\", dtype=None, **kwargs):\n",
    "        super().__init__(name=name, dtype=dtype, **kwargs)\n",
    "        self.accuracy = self.add_weight(name='acc', initializer='zeros')\n",
    "        self.n_classes = n_classes\n",
    "        self.training = tf.Variable(True)\n",
    "\n",
    "    def update_state(self, labels,logits):\n",
    "        probs = tf.nn.softmax(tf.reshape(logits, [-1, self.n_classes]))\n",
    "        if self.training:\n",
    "            labels = tf.reshape(labels, [-1])\n",
    "        else:\n",
    "            probs = tf.math.reduce_mean(probs, axis=1) \n",
    "\n",
    "        accuracy = tf.keras.metrics.sparse_categorical_accuracy(labels,probs)\n",
    "        self.accuracy.assign_add(accuracy)\n",
    "\n",
    "    def result(self):\n",
    "        return sefl.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToggleMetrics(tf.keras.callbacks.Callback):\n",
    "    '''On test begin (i.e. when evaluate() is called or \n",
    "     validation data is run during fit()) toggle metric flag '''\n",
    "    def on_test_begin(self, logs):\n",
    "        for metric in self.model.metrics:\n",
    "            if 'Accuracy' in metric.name:\n",
    "                metric.on.assign(False)\n",
    "    def on_test_end(self,  logs):\n",
    "        for metric in self.model.metrics:\n",
    "            if 'Accuracy' in metric.name:\n",
    "                metric.on.assign(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = (x_train.astype('float32') / 256 ) - 0.5\n",
    "x_test =(x_test.astype('float32') / 256 ) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 3\n",
    "d = 28\n",
    "w_mult = 10\n",
    "n_classes = 10\n",
    "epochs = 250\n",
    "batch_size = 128\n",
    "batch_rep = 4\n",
    "inp_rep_prob = 0.5\n",
    "input_shape = tuple([3]+ list(x_train[0].shape))\n",
    "val_split = 0.1\n",
    "l_2 = 3e-4\n",
    "steps_per_epoch = x_train.shape[0] * 1 - val_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 16:37:41.778279: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-26 16:37:41.778547: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-26 16:37:41.780556: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "traing_data=DataGenerator(x_train,y_train,batch_size,batch_rep,inp_rep_prob,ensemble_size,True)\n",
    "\n",
    "model = wide_resnet(input_shape,d,w_mult,n_classes, l_2)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=0.1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr_schedule)\n",
    "\n",
    "model.compile(optimizer,loss = NLL())\n",
    "#model.fit(traing_data,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=DataGenerator(x_test,y_test,batch_size,batch_rep,inp_rep_prob,ensemble_size,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 3, 32, 32, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 32, 32, 3, 3) 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 32, 9)    0           permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   1296        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 160)  23040       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 160)  640         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 160)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 160)  230400      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 160)  2560        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 160)  0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 160)  640         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 160)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 160)  230400      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 160)  640         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 160)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 160)  230400      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 160)  0           conv2d_5[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 160)  640         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 160)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 160)  230400      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 160)  640         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 160)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 160)  230400      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 160)  0           conv2d_7[0][0]                   \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 160)  640         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 160)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 160)  230400      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 160)  640         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 160)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 160)  230400      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 160)  0           conv2d_9[0][0]                   \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 160)  640         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 160)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 320)  460800      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 320)  1280        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 320)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 320)  921600      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 320)  51200       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 320)  0           conv2d_11[0][0]                  \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 320)  1280        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 320)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 320)  921600      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 320)  1280        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 320)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 320)  921600      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 320)  0           conv2d_14[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 320)  1280        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 320)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 320)  921600      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 320)  1280        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 320)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 320)  921600      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 320)  0           conv2d_16[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 320)  1280        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 320)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 320)  921600      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 320)  1280        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 320)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 320)  921600      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 320)  0           conv2d_18[0][0]                  \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 320)  1280        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 320)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 640)    1843200     activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 640)    2560        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 640)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 640)    3686400     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 640)    204800      add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 640)    0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 640)    2560        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 640)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 640)    3686400     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 640)    2560        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 640)    0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 640)    3686400     activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 640)    0           conv2d_23[0][0]                  \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 640)    2560        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 640)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 640)    3686400     activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 640)    2560        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 640)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 640)    3686400     activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 640)    0           conv2d_25[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 640)    2560        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 640)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 640)    3686400     activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 640)    2560        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 640)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 640)    3686400     activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 640)    0           conv2d_27[0][0]                  \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 640)    2560        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 640)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 640)    0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 640)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           19230       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 3, 10)        0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 36,510,830\n",
      "Trainable params: 36,492,878\n",
      "Non-trainable params: 17,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.random.uniform(size=[2,3,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = softmax(test,axis=2)\n",
    "np.sum(probs,axis=2)\n",
    "probs,np.mean(probs,axis=1)\n",
    "accuracy = tf.keras.metrics.sparse_categorical_accuracy(labels,probs) #Funkar detta?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = softmax(pred)\n",
    "    probs = np.mean(probs,axis=1)\n",
    "    accuracy = tf.keras.metrics.sparse_categorical_accuracy(labels,probs) #Funkar detta?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c7a171be4500626eafa29c013678d2d3ba3bac8c79e4ce1e00bc0ee886ad94e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
