{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input,Permute, Reshape, Conv2D, BatchNormalization, Activation,Add,AveragePooling2D,Flatten,Dense\n",
    "import time\n",
    "from tensorflow.keras.regularizers import l2,l1_l2\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.metrics import Mean,SparseCategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self,X,y,batch_size,batch_rep,inp_rep_prob,ensemble_size,training,shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size //batch_rep\n",
    "        self.shuffle = shuffle\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.batch_rep = batch_rep\n",
    "        self.inp_rep_prob = inp_rep_prob\n",
    "        self.n = X.shape[0]\n",
    "        self.training = training\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            idxs = np.arange(self.n)\n",
    "            np.random.shuffle(idxs)\n",
    "            self.X = self.X[idxs]\n",
    "            self.y = self.y[idxs]\n",
    "\n",
    "    def __get_train_data(self,imgs,labels):\n",
    "\n",
    "        batch_rep = np.tile(np.arange(imgs.shape[0]),[self.batch_rep])\n",
    "        np.random.shuffle(batch_rep)\n",
    "        input_shuffle=int(batch_rep.shape[0] * (1. - self.inp_rep_prob))\n",
    "        #Kan detta göras bättre?\n",
    "        shuffle_idxs = [np.concatenate([np.random.permutation( batch_rep[:input_shuffle]), batch_rep[input_shuffle:]]) for _ in range(self.ensemble_size)]\n",
    "\n",
    "        imgs = np.stack([np.take(imgs, indxs, axis=0) for indxs in shuffle_idxs], axis=1)\n",
    "        labels = np.stack([np.take(labels, indxs, axis=0) for indxs in shuffle_idxs], axis=1)\n",
    "        \n",
    "        return imgs, labels\n",
    "\n",
    "    def __get_test_data(self,imgs,labels):\n",
    "        imgs = np.tile(np.expand_dims(imgs, 1), [1, self.ensemble_size, 1, 1, 1])\n",
    "        \n",
    "        return imgs, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgs = self.X[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        labels = self.y[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        if self.training:\n",
    "            imgs, labels = self.__get_train_data(imgs,labels)\n",
    "        else:\n",
    "            imgs,labels = self.__get_test_data(imgs,labels)\n",
    "        return  imgs, labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(input,filters,strides,l_2):\n",
    "    y = input\n",
    "    x = BatchNormalization(momentum=0.9,epsilon=1e-5,beta_regularizer=l2(l_2),gamma_regularizer=l2(l_2))(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters,3,strides=strides,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(x)\n",
    "    x = BatchNormalization(momentum=0.9,epsilon=1e-5,beta_regularizer=l2(l_2),gamma_regularizer=l2(l_2))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters,3,strides=1,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(x)\n",
    "    \n",
    "    if not x.shape.is_compatible_with(y.shape):\n",
    "        y = Conv2D(filters,1,strides=strides,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(input)\n",
    "\n",
    "    return Add()([x,y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_group(input,filters,strides,n_blocks,l_2):\n",
    "    x = basic_block(input,filters,strides,l_2)\n",
    "    for _ in range(n_blocks-1):\n",
    "        x = basic_block(x,filters,1,l_2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_resnet(input_shape,d,w_mult,n_classes,l_2=0):\n",
    "    n_blocks = (d - 4) // 6\n",
    "    input_shape = list(input_shape)\n",
    "    ensemble_size = input_shape[0]\n",
    "\n",
    "    input = Input(shape=input_shape)\n",
    "\n",
    "    x = Permute([2,3,4,1])(input)\n",
    "\n",
    "    # Reshape so that each subnetwork has 3 channels\n",
    "    x = Reshape(input_shape[1:-1] + [input_shape[-1] * ensemble_size])(x)\n",
    "\n",
    "    x = Conv2D(16,3,padding ='same',use_bias=False,kernel_initializer=\"he_normal\",kernel_regularizer=l2(l_2))(x)\n",
    "\n",
    "    for strides, filters in zip([1, 2, 2], [16, 32, 64]):\n",
    "        x = res_group(x,filters*w_mult,strides,n_blocks,l_2)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9,epsilon=1e-5,beta_regularizer=l2(l_2),gamma_regularizer=l2(l_2))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(n_classes*ensemble_size,kernel_initializer='he_normal',activation=None,kernel_regularizer=l2(l_2),bias_regularizer=l2(l_2))(x)\n",
    "    x = Reshape([ensemble_size,n_classes])(x)\n",
    "    \n",
    "    return tf.keras.Model(input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLL(Loss):\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "        nll = tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = (x_train.astype('float32') / 256 ) - 0.5\n",
    "x_test =(x_test.astype('float32') / 256 ) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_size = 3\n",
    "d = 28\n",
    "w_mult = 10\n",
    "n_classes = 10\n",
    "epochs = 250\n",
    "batch_size = 256\n",
    "batch_rep = 4\n",
    "inp_rep_prob = 0.5\n",
    "input_shape = tuple([3]+ list(x_train[0].shape))\n",
    "val_split = 0.1\n",
    "l_2 = 3e-4\n",
    "steps_per_epoch = x_train.shape[0] * 1 - val_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-17 12:18:47.019646: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-17 12:18:47.020002: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-17 12:18:47.029846: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2021-11-17 12:18:47.858561: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-17 12:18:47.878994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    }
   ],
   "source": [
    "traing_data=DataGenerator(x_train,y_train,batch_size,batch_rep,inp_rep_prob,ensemble_size,True)\n",
    "\n",
    "model = wide_resnet(input_shape,d,w_mult,n_classes, l_2)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.1,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=0.1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr_schedule)\n",
    "\n",
    "model.compile(optimizer,loss = NLL())\n",
    "model.fit(traing_data,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=DataGenerator(x_test,y_test,batch_size,batch_rep,inp_rep_prob,ensemble_size,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19572/3470139634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c7a171be4500626eafa29c013678d2d3ba3bac8c79e4ce1e00bc0ee886ad94e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('dl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
